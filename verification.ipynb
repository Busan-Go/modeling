{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPjVW/X/FFDg+XMy9nhS0un"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"id":"KJMwdfUxOc8k","executionInfo":{"status":"error","timestamp":1699553432081,"user_tz":-540,"elapsed":4,"user":{"displayName":"윤금재","userId":"05441756190857347421"}},"outputId":"a1d33de6-b24c-4709-8236-4ed07ae7e9d9"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-473e095eb14b>\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mpickle_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"image_test_dict.pickle\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0minference_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVerificationModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeyword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-473e095eb14b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_path, pickle_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mVerificationModel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'efficientnet_b0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     self.model.classifier = nn.Sequential(\n\u001b[1;32m      5\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1280\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'timm' is not defined"]}],"source":["!pip install timm\n","import torch\n","import torch.nn as nn\n","from torchvision import transforms\n","import timm\n","import unicodedata\n","import cv2\n","from PIL import Image\n","\n","class VerificationModel:\n","  def __init__(self, model_path, pickle_path):\n","    self.model = timm.create_model('efficientnet_b0', pretrained=True)\n","    self.model.classifier = nn.Sequential(\n","        nn.Linear(1280, 512),\n","        nn.ReLU(),\n","        nn.Linear(512, 128),\n","    )\n","    checkpoint = torch.load(model_path)\n","    self.model.load_state_dict(checkpoint)\n","    self.model.eval()  # Set the model to inference mode\n","\n","    with open(pickle_path, 'rb') as handle:\n","        self.image_test_dict = pickle.load(handle)\n","\n","    self.transform = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    ])\n","\n","  def data_load(self, input_path):\n","    data = cv2.imread(input_path)\n","    data = cv2.cvtColor(data, cv2.COLOR_BGR2RGB)\n","    data = cv2.resize(data, (224, 224))\n","    data = Image.fromarray(data)\n","    data = self.transform(data)\n","    return data.unsqueeze(dim=0)\n","\n","  def predict(self, input_path, keyword):\n","    data = self.data_load(input_path)\n","    output1 = self.image_test_dict[keyword]\n","    output2 = self.model(data)\n","    n = output1.shape[0]\n","    output2 = torch.cat([output2] * n)\n","\n","    count = sum(torch.pow(output1 - output2, 2).sum(dim=1).sqrt() < 0.68)\n","    result = (count >= 1).int()\n","    return result.item()\n","\n","# input_path = 입력 이미지 경로\n","# keyword = 해당 장소\n","\n","model_path = './best_model.pth'\n","pickle_path = \"image_test_dict.pickle\"\n","\n","inference_model = VerificationModel(model_path, pickle_path)\n","result = inference_model.predict(input_path, keyword)\n","print(result)"]},{"cell_type":"code","source":[],"metadata":{"id":"Xu4cfXjyRwvW"},"execution_count":null,"outputs":[]}]}